{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lex-gh.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('corpus')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import sys, os\n",
        "import random, math\n",
        "\n",
        "def reverse_sent(sent):\n",
        "  max_tries = 10\n",
        "  tries = 0\n",
        "  while True:\n",
        "    tok = nltk.word_tokenize(sent.lower())\n",
        "    if tok[-1] == '.':\n",
        "      last = tok[-1]\n",
        "      new_tok = tok[:-1]\n",
        "      new_tok = new_tok[::-1] # Reverse\n",
        "      new_tok = new_tok + [last]\n",
        "    else:\n",
        "      new_tok = tok\n",
        "      new_tok = new_tok[::-1] # Reverse\n",
        "    new_sent = ' '.join(new_tok )\n",
        "    if new_sent != sent:\n",
        "        break\n",
        "    elif tries >= max_tries:\n",
        "        break\n",
        "    else:\n",
        "        tries +=1\n",
        "        continue\n",
        "  if new_sent==sent:\n",
        "      return float('NaN')\n",
        "  else:\n",
        "      return new_sent\n",
        "\n",
        "def shuffle_sent(sent):\n",
        "  max_tries = 10\n",
        "  tries = 0\n",
        "\n",
        "  while True:\n",
        "    tok = nltk.word_tokenize(sent.lower())\n",
        "    if tok[-1] == '.':\n",
        "\n",
        "      last = tok[-1]\n",
        "      new_tok = tok[:-1]\n",
        "      random.shuffle(new_tok)\n",
        "      new_tok = new_tok + [last]\n",
        "    else:\n",
        "      random.shuffle(tok)\n",
        "      new_tok = tok\n",
        "      \n",
        "    \n",
        "    new_sent = ' '.join(new_tok )\n",
        "    if new_sent != sent:\n",
        "      break\n",
        "    elif tries >= max_tries:\n",
        "      break\n",
        "    else:\n",
        "      tries +=1\n",
        "      continue\n",
        "  if new_sent==sent:\n",
        "      return float('NaN')\n",
        "  else:\n",
        "      return new_sent\n",
        "\n",
        "def sort_sent(sent):\n",
        "    max_tries = 10\n",
        "    tries = 0\n",
        "\n",
        "    while True:\n",
        "        tok = nltk.word_tokenize(sent.lower())\n",
        "        if tok[-1] == '.':\n",
        "            last = tok[-1]\n",
        "            new_tok = tok[:-1]\n",
        "            new_tok.sort() # Sort step\n",
        "            new_tok = new_tok + [last]\n",
        "        else:\n",
        "            new_tok = tok\n",
        "            new_tok.sort() # Sort step\n",
        "        new_sent = ' '.join(new_tok )\n",
        "        if new_sent != sent:\n",
        "            break\n",
        "        elif tries >= max_tries:\n",
        "            break\n",
        "        else:\n",
        "            tries +=1\n",
        "            continue\n",
        "    if new_sent==sent:\n",
        "      return float('NaN')\n",
        "    else:\n",
        "      return new_sent\n",
        "\n",
        "def copysort(row):\n",
        "    tok = nltk.word_tokenize(row['query'])\n",
        "    tok.sort()\n",
        "    if ' '.join(tok) == row['candidate']:\n",
        "      return float('NaN')\n",
        "    else:\n",
        "      return ' '.join(tok)\n",
        "\n",
        "\n",
        "#for reverse, shuffle, sort operations\n",
        "test_data = pd.read_csv(path_to_test_data) # insert path\n",
        "for function in [sort_sent, shuffle_sent, reverse_sent]:\n",
        "  test_copy = test_data.copy()\n",
        "  test_copy['perturbed query'] = test_copy('query').apply(function)\n",
        "  test_copy.dropna(inplace=True)\n",
        "  test_copy.drop_duplicates(inplace=True)\n",
        "  test_copy.reset_index(drop=True, inplace=True)\n",
        "  test_copy.to_csv(f\"{function}-perturbed-query.csv\")\n",
        "\n",
        "#for copysort\n",
        "function = copysort\n",
        "test_copy = test_data.copy()\n",
        "test_copy['perturbed query'] = test_copy.apply(function, axis=1)\n",
        "test_copy.dropna(inplace=True)\n",
        "test_copy.drop_duplicates(inplace=True)\n",
        "test_copy.reset_index(drop=True, inplace=True)\n",
        "test_copy.to_csv(f\"{function}-perturbed-query.csv\")"
      ],
      "metadata": {
        "id": "fnXPV6kSG6iL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
